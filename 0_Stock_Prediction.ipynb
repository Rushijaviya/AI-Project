{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6144,"status":"ok","timestamp":1650877892023,"user":{"displayName":"201951065 GHASADIYA MANTHAN JITESHBHAI","userId":"07078768666322572720"},"user_tz":-330},"id":"SeL3Ab6igvuS","outputId":"9e43dd93-4132-4e31-a37a-f53cb6ca4da8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1650877892024,"user":{"displayName":"201951065 GHASADIYA MANTHAN JITESHBHAI","userId":"07078768666322572720"},"user_tz":-330},"id":"-288Z_YLjr-_","outputId":"761e4157-c027-43dd-d0db-6d53ad0570d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["           Date          Open          High           Low         Close  \\\n","0    2021-04-26  14449.450195  14557.500000  14421.299805  14485.000000   \n","1    2021-04-27  14493.799805  14667.549805  14484.849609  14653.049805   \n","2    2021-04-28  14710.500000  14890.250000  14694.950195  14864.549805   \n","3    2021-04-29  14979.000000  15044.349609  14814.450195  14894.900391   \n","4    2021-04-30  14747.349609  14855.450195  14601.700195  14631.099609   \n","..          ...           ...           ...           ...           ...   \n","243  2022-04-18  17183.449219  17237.750000  17067.849609  17173.650391   \n","244  2022-04-19  17258.949219  17275.650391  16824.699219  16958.650391   \n","245  2022-04-20  17045.250000  17186.900391  16978.949219  17136.550781   \n","246  2022-04-21  17234.599609  17414.699219  17215.500000  17392.599609   \n","247  2022-04-22  17242.750000  17315.300781  17149.199219  17171.949219   \n","\n","        Adj Close  Volume  \n","0    14485.000000  452700  \n","1    14653.049805  451800  \n","2    14864.549805  457000  \n","3    14894.900391  517500  \n","4    14631.099609  613900  \n","..            ...     ...  \n","243  17173.650391  376100  \n","244  16958.650391  401400  \n","245  17136.550781  286100  \n","246  17392.599609  285200  \n","247  17171.949219  262700  \n","\n","[248 rows x 7 columns]\n"]}],"source":["import pandas as pd\n","data=pd.read_csv(\"/content/drive/Shareddrives/M G/AI/NSEI.csv\")\n","print(data)"]},{"cell_type":"markdown","metadata":{"id":"ek-DhBtmCTnp"},"source":["# Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZTen0CmjtvK"},"outputs":[],"source":["import keras\n","from keras.models import Sequential\n","from keras.models import load_model\n","from keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","import numpy as np\n","import random\n","from collections import deque\n","\n","class Agent:\n","\tdef __init__(self, state_size, is_eval=False, model_name=\"\"):\n","\t\tself.state_size = state_size # normalized previous days\n","\t\tself.action_size = 3 # sit, buy, sell\n","\t\tself.memory = deque(maxlen=1000)\n","\t\tself.inventory = []\n","\t\t# self.model_name = \"model_ep2\"\n","\t\tself.is_eval = is_eval\n","\n","\t\tself.gamma = 0.95\n","\t\tself.epsilon = 1.0\n","\t\tself.epsilon_min = 0.01\n","\t\tself.epsilon_decay = 0.995\n","\n","\t\tself.model = load_model(\"/content/drive/Shareddrives/M G/AI/model_ep7\") if is_eval else self._model()\n","\n","\tdef _model(self):\n","\t\tmodel = Sequential()\n","\t\tmodel.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n","\t\tmodel.add(Dense(units=32, activation=\"relu\"))\n","\t\tmodel.add(Dense(units=8, activation=\"relu\"))\t\n","\t\tmodel.add(Dense(self.action_size, activation=\"linear\"))\n","\t\tmodel.compile(loss=\"mse\", optimizer=Adam(lr=0.001)) \n","\n","\t\treturn model\n","\n","\tdef act(self, state): # predict the next action to be taken (sell, buy)\n","\t\tif not self.is_eval and random.random() <= self.epsilon:\n","\t\t\treturn random.randrange(self.action_size)\n","\n","\t\toptions = self.model.predict(state)\n","\t\treturn np.argmax(options[0])\n","\n","\tdef expReplay(self, batch_size): # if memory gets full it will reset the memory\n","\t\tmini_batch = []\n","\t\tl = len(self.memory)\n","\t\tfor i in range(l - batch_size + 1, l):\n","\t\t\tmini_batch.append(self.memory[i])\n","\n","\t\tfor state, action, reward, next_state, done in mini_batch:\n","\t\t\ttarget = reward\n","\t\t\tif not done:\n","\t\t\t\ttarget = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n","\n","\t\t\ttarget_f = self.model.predict(state)\n","\t\t\ttarget_f[0][action] = target\n","\t\t\tself.model.fit(state, target_f, epochs=1, verbose=0)\n","\n","\t\tif self.epsilon > self.epsilon_min:\n","\t\t\tself.epsilon *= self.epsilon_decay "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p27Q91yjjuq9"},"outputs":[],"source":["import numpy as np\n","import math\n","\n","# prints formatted price\n","def formatPrice(n):\n","\treturn (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n","\n","# returns the vector containing stock data from a fixed file\n","def getStockDataVec():\n","\tvec = []\n","\tlines = open(\"/content/drive/Shareddrives/M G/AI/NSEI.csv\", \"r\").read().splitlines()\n","\n","\tfor line in lines[1:]:\n","\t\tvec.append(float(line.split(\",\")[4]))\n","\n","\treturn vec\n","\n","# returns the sigmoid\n","\n","\n","\n","def sigmoid(x):\n","\ttry:\n","\t\treturn 1 / (1 + math.exp(-x))\n","\texcept OverflowError:\n","\t\tans = float('inf')\n","\t\treturn 0\n","\n","# returns an an n-day state representation ending at time t\n","def getState(data, t, n):\n","\td = t - n + 1\n","\tblock = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # predicting the model on consecutive days difference\n","\tres = []\n","\tfor i in range(n - 1):\n","\t\tres.append(sigmoid(block[i + 1] - block[i]))\n","\n","\treturn np.array([res])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":831},"executionInfo":{"elapsed":25720,"status":"error","timestamp":1650877843584,"user":{"displayName":"201951065 GHASADIYA MANTHAN JITESHBHAI","userId":"07078768666322572720"},"user_tz":-330},"id":"QGj-fKtoj6Oe","outputId":"a0d124e6-2668-45d1-e94b-e25829e59db6"},"outputs":[],"source":["# from agent.agent import Agent\n","# from functions import *\n","import sys\n","\n","if len(sys.argv) != 4:\n","\tprint(\"Usage: python train.py [stock] [window] [episodes]\")\n","\texit()\n","\n","\n","window_size = 10 # 10 days stocks to count the difference\n","episode_count = 10\n","agent = Agent(window_size)\n","data = getStockDataVec()\n","l = len(data) - 1\n","batch_size = 32 #\n","\n","for e in range(episode_count + 1):\n","\tprint(\"Episode \" + str(e) + \"/\" + str(episode_count))\n","\tstate = getState(data, 0, window_size + 1)\n","\n","\ttotal_profit = 0\n","\tagent.inventory = []\n","\n","\tfor t in range(l):\n","\t\taction = agent.act(state)\n","\n","\t\t# sit\n","\t\tnext_state = getState(data, t + 1, window_size + 1)\n","\t\treward = 0\n","\n","\t\tif action == 1: # buy\n","\t\t\tagent.inventory.append(data[t])\n","\t\t\tprint(\"Buy: \" + formatPrice(data[t]))\n","\n","\t\telif action == 2 and len(agent.inventory) > 0: # sell\n","\t\t\tbought_price = agent.inventory.pop(0)\n","\t\t\treward = max(data[t] - bought_price, 0)\n","\t\t\ttotal_profit += data[t] - bought_price\n","\t\t\tprint(\"Sell: \" + formatPrice(data[t]) + \" | Profit: \" + formatPrice(data[t] - bought_price))\n","\n","\t\tdone = True if t == l - 1 else False\n","\t\tagent.memory.append((state, action, reward, next_state, done))\n","\t\tstate = next_state\n","\n","\t\tif done:\n","\t\t\tprint(\"--------------------------------\")\n","\t\t\tprint(\"Total Profit: \" + formatPrice(total_profit))\n","\t\t\tprint(\"--------------------------------\")\n","\n","\t\tif len(agent.memory) > batch_size:\n","\t\t\tagent.expReplay(batch_size)\n","\n","\tif e % 2 == 0:\n","\t\tagent.model.save(\"/content/drive/Shareddrives/M G/AI\" + str(e))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13861,"status":"ok","timestamp":1650877912203,"user":{"displayName":"201951065 GHASADIYA MANTHAN JITESHBHAI","userId":"07078768666322572720"},"user_tz":-330},"id":"tbJfZQ9PkGBz","outputId":"5f1847d2-e974-4d87-e79b-08ae4bffd2ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Buy: $17101.95\n","Buy: $17339.85\n","Sell: $17576.85 | Profit: $474.90\n","Sell: $17780.00 | Profit: $440.15\n","Buy: $16247.95\n","Buy: $16658.40\n","Sell: $16793.90 | Profit: $545.95\n","Buy: $16498.05\n","Buy: $16245.35\n","Buy: $15863.15\n","Sell: $16013.45 | Profit: -$644.95\n","Sell: $16345.35 | Profit: -$152.70\n","Sell: $16630.45 | Profit: $385.10\n","Sell: $16871.30 | Profit: $1008.15\n","--------------------------------\n"," Total Profit: $2056.60\n","--------------------------------\n"]}],"source":["import keras\n","from keras.models import load_model\n","\n","# from agent.agent import Agent\n","# from functions import *\n","import sys\n","\n","if len(sys.argv) != 3:\n","\tprint(\"Usage: python evaluate.py [stock] [model]\")\n","\texit()\n","opy the content of file 'file.txt' to file 'file2.txt'\n","model = load_model(\"/content/drive/Shareddrives/M G/AI/model_ep7\")\n","window_size = model.layers[0].input.shape.as_list()[1]\n","\n","agent = Agent(window_size, True)\n","data = getStockDataVec()\n","l = len(data) - 1\n","batch_size = 32\n","\n","state = getState(data, 0, window_size + 1)\n","# print(state)\n","\n","total_profit = 0\n","agent.inventory = []\n","\n","\n","for t in range(l):\n","\taction = agent.act(state)\n","\t# print(action)\n","\t# sit\n","\tnext_state = getState(data, t + 1, window_size + 1)\n","\treward = 0\n","\n","\tif action == 1: # buy\n","\t\tagent.inventory.append(data[t])\n","\t\tprint(\"Buy: \" + formatPrice(data[t]))\n","\n","\telif action == 2 and len(agent.inventory) > 0: # sell\n","\t\tbought_price = agent.inventory.pop(0)\n","\t\treward = max(data[t] - bought_price, 0)\n","\t\ttotal_profit += data[t] - bought_price\n","\t\tprint(\"Sell: \" + formatPrice(data[t]) + \" | Profit: \" + formatPrice(data[t] - bought_price))\n","\n","\tdone = True if t == l - 1 else False\n","\tagent.memory.append((state, action, reward, next_state, done))\n","\tstate = next_state\n","\n","\tif done:\n","\t\tprint(\"--------------------------------\")\n","\t\tprint( \" Total Profit: \" + formatPrice(total_profit))\n","\t\tprint(\"--------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZzIS5NmRtIw"},"outputs":[],"source":["# Buy: $3476.40\n","# Buy: $3484.20\n","# Sell: $3492.25 | Profit: $15.85\n","# Sell: $3508.65 | Profit: $24.45\n","# --------------------------------\n","#  Total Profit: $40.30\n","# -------------------------------\n","\n","# model ep 7\n","# Buy: $17101.95\n","# Buy: $17339.85\n","# Sell: $17576.85 | Profit: $474.90\n","# Sell: $17780.00 | Profit: $440.15\n","# Buy: $16247.95\n","# Buy: $16658.40\n","# Sell: $16793.90 | Profit: $545.95\n","# Buy: $16498.05\n","# Buy: $16245.35\n","# Buy: $15863.15\n","# Sell: $16013.45 | Profit: -$644.95\n","# Sell: $16345.35 | Profit: -$152.70\n","# Sell: $16630.45 | Profit: $385.10\n","# Sell: $16871.30 | Profit: $1008.15\n","# --------------------------------\n","#  Total Profit: $2056.60\n","# --------------------------------"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"0_Stock_Prediction.ipynb","provenance":[{"file_id":"1Bsx4Fz7NpiX4BgWYpg53RBkAKQTtduop","timestamp":1650734293177}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
